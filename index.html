<!DOCTYPE html>
<html lang="en">

<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="">
    <meta name="author" content="">

    <title>Foresight | Machine Learning-Powered Glaucoma Detection</title>

    <!-- Bootstrap Core CSS -->
    <link href="vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom Fonts -->
    <link href="vendor/font-awesome/css/font-awesome.min.css" rel="stylesheet" type="text/css">
    <link href="https://fonts.googleapis.com/css?family=Montserrat:400,700" rel="stylesheet" type="text/css">
    <link href='https://fonts.googleapis.com/css?family=Kaushan+Script' rel='stylesheet' type='text/css'>
    <link href='https://fonts.googleapis.com/css?family=Droid+Serif:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
    <link href='https://fonts.googleapis.com/css?family=Roboto+Slab:400,100,300,700' rel='stylesheet' type='text/css'>

    <!-- Theme CSS -->
    <link href="css/agency.min.css" rel="stylesheet">
    <link href="css/custom.css" rel="stylesheet">

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js" integrity="sha384-0s5Pv64cNZJieYFkXYOTId2HMA2Lfb6q2nAcx2n0RTLUnCAoTTsS0nKEO27XyKcY" crossorigin="anonymous"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js" integrity="sha384-ZoaMbDF+4LeFxg6WdScQ9nnR1QC2MIRxA1O9KWEXQwns1G8UNyIEZIQidzb0T1fo" crossorigin="anonymous"></script>
    <![endif]-->

</head>

<body id="page-top" class="index">

    <!-- Navigation -->
    <nav id="mainNav" class="navbar navbar-default navbar-custom navbar-fixed-top">
        <div class="container">
            <!-- Brand and toggle get grouped for better mobile display -->
            <div class="navbar-header page-scroll">
                <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
                    <span class="sr-only">Toggle navigation</span> Menu <i class="fa fa-bars"></i>
                </button>
                <a class="navbar-brand page-scroll" href="#page-top">Foresight</a>
            </div>

            <!-- Collect the nav links, forms, and other content for toggling -->
            <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
                <ul class="nav navbar-nav navbar-right">
                    <li class="hidden">
                        <a href="#page-top"></a>
                    </li>
                    <li>
                        <a class="page-scroll black" href="#about">What is Foresight?</a>
                    </li>
                    <li>
                        <a class="page-scroll black" href="#data">Data</a>
                    </li>
                    <li>
                        <a class="page-scroll black" href="#portfolio">Research & Analysis</a>
                    </li>
                    <li>
                        <a class="page-scroll black" href="#results">Results</a>
                    </li>
                    <li>
                        <a class="page-scroll black" href="#nextsteps">Next Steps</a>
                    </li>
                    <li>
                        <a class="page-scroll black" href="#team">Team</a>
                    </li>
                    <li>
                        <a class="page-scroll black" href="#advisors">Advisors</a>
                    </li>

                </ul>
            </div>
            <!-- /.navbar-collapse -->
        </div>
        <!-- /.container-fluid -->
    </nav>

    <!-- Header -->
    <header>
        <div class="header-overlay">
            <div class="container">
                <div class="intro-text">
                    <div class="intro-heading">Foresight</div>
                    <div class="intro-lead-in">Machine learning-powered glaucoma detection</div>
                    <a href=" http://54.172.11.223:8080" target="_blank" class="page-scroll btn btn-xl black">View demo</a>
                </div>
            </div>
        </div>
    </header>

    <!-- About Section -->
    <section id="about">
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2 class="section-heading">Glaucoma is a leading cause of <br> blindness and has no cure</h2>
                    <h3 class="section-subheading text-muted"></h3>
                </div>
            </div>
            <div class="row text-center">
                <div class="col-md-4">
                    <span class="fa-stack fa-4x">
                        <i class="fa fa-circle fa-stack-2x text-primary"></i>
                        <i class="fa fa-users fa-stack-1x fa-inverse"></i>
                    </span>
                    <h4 class="service-heading">60M affected <br> worldwide</h4>
                    <p class="text-muted">Glaucoma is the leading cause of <br> irreversible blindness worldwide</p>
                </div>
                <div class="col-md-4">
                    <span class="fa-stack fa-4x">
                        <i class="fa fa-circle fa-stack-2x text-primary"></i>
                        <i class="fa fa-dollar fa-stack-1x fa-inverse"></i>
                    </span>
                    <h4 class="service-heading">$2.5B in annual <br> US healthcare spend</h4>
                    <p class="text-muted">Glaucoma testing and treatment drives <br> 10M physician visits in the US each year</p>
                </div>
                <div class="col-md-4">
                    <span class="fa-stack fa-4x">
                        <i class="fa fa-circle fa-stack-2x text-primary"></i>
                        <i class="fa fa-wheelchair fa-stack-1x fa-inverse"></i>
                    </span>
                    <h4 class="service-heading">1 in 8 go blind <br> even with treatment</h4>
                    <p class="text-muted">Determining the speed of vision deterioration <br> early is critical to preventing blindness</p>
                </div>
            </div>
        </div>
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2 class="section-heading"></h2>
                    <h3 class="section-subheading text-muted"></h3>
                </div>
            </div>
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2 class="section-heading">Today glaucoma detection is <br> uncertain and friction-filled</h2>
                    <h3 class="section-subheading text-muted"></h3>
                </div>
            </div>
            <div class="row text-center">
                <div class="col-md-6">
                    <img src="img/greyscale.png" class="img-responsive img-square" alt="results">
                </div>
                <div class="col-md-6">
                    <h4 class="demo-heading" align="left">Is the patient's vision getting worse ("progressing")?</h4>
                    <p class="text-muted" align="left"><a class="text-link" href = "http://www.eyerounds.org/tutorials/VF-testing/index.htm" target="_blank"> Visual field tests </a> that detect a patient's sensitivity to light at 54 distinct points are a critical factor in determining the right treatment strategy for glaucoma. </p>
                    <p class="text-muted" align="left">3 key reasons complicate interpreting results to determine progression: </p>
                    <p class="text-muted" align="left">
                    <li> <strong> Test Variation: </strong> Visual field tests depend on patient responses to flashes of light. Patient fatigue, lack of focus, or learning effects can cause variation in the results independent of any change in vision </li>
                    <li> <strong> Lack of a "gold standard" metric: </strong> Researchers have developed a range of metrics for assessing patient vision. Research has shown that these measures can often disagree leaving clinicians to make a judgement call between them  </li>
                    <li> <strong> Too manual: </strong> Today clinicians line up paper printouts of visual field results to compare results over time and make assessments on pateient progression </li>
                    </p>
                </div>
            </div>
            <br><br>
            <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2 class="section-heading"></h2>
                    <h3 class="section-subheading text-muted"></h3>
                </div>
            </div>
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2 class="section-heading">Foresight aims to bring simplicity and certainty to glaucoma detection
                    <h3 class="section-subheading text-muted"></h3>
                </div>
            </div>
             <div class="row text-center">
                <div class="col-md-6">
                    <br>
                    <h4 class="demo-heading" align="left">More accurate detection</h4>
                    <p class="text-muted" align="left">Leverage machine learning on 13K unique eyes across 5 leading US eye institutes</p><br>
                    <h4 class="demo-heading" align="left">Streamlined data consumption</h4>
                    <p class="text-muted" align="left">Eliminate the clutter to help clinicians determine the right treatment strategy</p><br>
                    <h4 class="demo-heading" align="left">Put patient data in context</h4>
                    <p class="text-muted" align="left">Give clinicians confidence in recommendations by placing data in relation to patient history and peers</p>
                </div>
                <div class="col-md-6">
                    <img src="img/web_app.png" class="img-responsive img-square" alt="results">
                </div>
            </div>
        </div>

    </section>

    <!-- Data Section -->
    <section id="data" class="bg-light-gray">
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2 class="section-heading">Data</h2>
                    <h3 class="section-subheading text-muted">Understanding how data on patient vision is structured</h3>
                </div>
            </div>
            <div class="row text-center">
                <div class="col-md-4">
                    <img src="img/visual_field_clean.png" class="img-responsive img-square" alt="results">
                    <p class="text-muted" > Visual field of right eye <br> (total deviation values shown)</p>
                    <p class="text-muted" style = "font-size: 12px"><i> note: black rectangle represents blind spot </p></i>
                </div>
                <div class="col-md-8">
                    <h4 class="demo-heading" align="left">A visual field is the core data structure for our product </h4>
                    <p class="text-muted" align="left">Numbers in the eye-shaped matrix represent a patient's sensitivity to light at 54-distinct points. Higher numbers represent stronger vision. There are three standard metrics on visual fields, which are included in our dataset:</p>
                    <p class="text-muted" align="left">
                    <li> <strong> Raw sensitivity: </strong> values of each tested point are listed in decibels in the sensitivity plot. Higher numbers mean the patient was able to see a more attenuated light, and thus has more sensitive vision at that location</li>
                    <li> <strong> Total deviation: </strong> values are deviations in sensitivity from the expected values for a specific age. Positive values represent areas of the field where the patient can see dimmer stimuli than the average individual of that age. Negative values represent decreased sensitivity from normal. </li>
                    <li> <strong> Pattern deviation: </strong> total deviation values corrected for generalized decreases in visual sensitivity. It is useful in cases where there is both localized depression due to glaucoma, as well as globally depressed vision across the eye due to other pathologies such as cataracts. </li>
                    </p><br>
                    <h4 class="demo-heading" align="left">Our dataset consists of 831K visual fields from 177K unique patients spanning 5 US-based eye institutes.</h4>
                    <p class="text-muted" align="left">
                    <li>Eyes from the Glaucoma Research Network visual field collection (831,240 fields from five sites without clinical data) were used </li>
                    <li>Dataset was filtered for patients with at least five reliable, SITA-Standard 24-2 fields resulting in 90,713 fields of 13,156 eyes included in the study.</li>
                </div>
            </div>
        </div>
    </section>


    <!-- Research & Analysis Grid Section -->
    <!-- See below for in the "Portfolio Modals" Section for editing the 'on-click' content -->
    <section class="portfolio-container">
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2 class="section-heading">Research & Analysis</h2>
                    <h3 class="section-subheading text-muted">Leveraging insights from clinicians, glaucoma research and machine learning techniques to develop Foresight</h3>
                </div>
            </div>
            <div class="row">
                <div class="col-md-4 col-sm-6 portfolio-item">
                    <a href="#portfolioModal1" class="portfolio-link" data-toggle="modal">
                        <div class="portfolio-hover">
                            <div class="portfolio-hover-content">
                                <i class="fa fa-plus fa-3x"></i>
                            </div>
                        </div>
                        <img src="img/portfolio/user_research.png" class="img-responsive" alt="">
                    </a>
                    <div class="portfolio-caption">
                        <h4>#1: User research</h4>
                    </div>
                </div>
                <div class="col-md-4 col-sm-6 portfolio-item">
                    <a href="#portfolioModal2" class="portfolio-link" data-toggle="modal">
                        <div class="portfolio-hover">
                            <div class="portfolio-hover-content">
                                <i class="fa fa-plus fa-3x"></i>
                            </div>
                        </div>
                        <img src="img/portfolio/filtering_graph.png" class="img-responsive" alt="">
                    </a>
                    <div class="portfolio-caption">
                        <h4>#2: Data filtering</h4>
                    </div>
                </div>
                <div class="col-md-4 col-sm-6 portfolio-item">
                    <a href="#portfolioModal3" class="portfolio-link" data-toggle="modal">
                        <div class="portfolio-hover">
                            <div class="portfolio-hover-content">
                                <i class="fa fa-plus fa-3x"></i>
                            </div>
                        </div>
                        <img src="img/portfolio/exploring_data.png" class="img-responsive" alt="">
                    </a>
                    <div class="portfolio-caption">
                        <h4>#3: Data exploration</h4>
                    </div>
                </div>
                <div class="col-md-4 col-sm-6 portfolio-item">
                    <a href="#portfolioModal4" class="portfolio-link" data-toggle="modal">
                        <div class="portfolio-hover">
                            <div class="portfolio-hover-content">
                                <i class="fa fa-plus fa-3x"></i>
                            </div>
                        </div>
                        <img src="img/portfolio/normalizing.png" class="img-responsive" alt="">
                    </a>
                    <div class="portfolio-caption">
                        <h4>#4: Data normalization</h4>
                    </div>
                </div>
                <div class="col-md-4 col-sm-6 portfolio-item">
                    <a href="#portfolioModal5" class="portfolio-link" data-toggle="modal">
                        <div class="portfolio-hover">
                            <div class="portfolio-hover-content">
                                <i class="fa fa-plus fa-3x"></i>
                            </div>
                        </div>
                        <img src="img/portfolio/generating_labels_1.png" class="img-responsive" alt="">
                    </a>
                    <div class="portfolio-caption">
                        <h4>#5: Label generation</h4>
                    </div>
                </div>
                <div class="col-md-4 col-sm-6 portfolio-item">
                    <a href="#portfolioModal6" class="portfolio-link" data-toggle="modal">
                        <div class="portfolio-hover">
                            <div class="portfolio-hover-content">
                                <i class="fa fa-plus fa-3x"></i>
                            </div>
                        </div>
                        <img src="img/portfolio/generating_models.png" class="img-responsive" alt="">
                    </a>
                    <div class="portfolio-caption">
                        <h4>#6: Model development</h4>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Results Section -->
    <section id="results" class="bg-light-gray">
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2 class="section-heading">Results</h2>
                    <h3 class="section-subheading text-muted">Benchmarking our model against leading research standards</h3>
                </div>
            </div>
            <div class="row text-center">
                <div class="col-md-6">
                    <img src="img/results4.png" class="img-responsive img-square" style="vertical-align:bottom" alt="results">
                </div>
                <div class="col-md-6">
                    <br><br><img src="img/class_biased_classifier.jpg" class="img-responsive img-square" style="vertical-align:bottom" alt="class-bias">
                </div>
            </div>
            <div class="row text-center">
                <div class="col-md-12">
                    <p align = left>
                    <br><br>
                    <h4><strong>200 expert-labeled patients used to benchmark our models </strong></h4>
                    <ul>
                        <li> 200 patients chosen randomly in each of three categories based on proxy label (50 unanimous "stable", 50 unanimous "progressing", 100 where algorithms disagreed) </li>
                        <li> Human ophthalmologist (glaucoma expert) examined visual fields of these patients and generated "ground truth". </li>
                        <li> Ground Truth: 134 out of 200 patients had "progressing" or "stable". The remaining 66 were boundary cases </li>
                    </ul>
                    <br>
                    </p>
                </div>
            </div>
            <div class="row text-center">
                <div class="col-md-6">
                    <h4 class="demo-heading"><strong>Foresight classifiers have good F1 scores with lower class-bias</strong></h4>
                    <li><strong>Encouraging F1 scores: </strong> Our top 4 classifiers had F1 scores in line with leading research algorithms (i.e., 0.90 or above) </li>
                    <li><strong>Lower Class-Bias: </strong> Our classifiers did not overpredict "progressing" on patients identified as "too close to call" by the glaucoma specialist, while VFI and PLR did.</li>
                </div>
                <div class="col-md-6">
                    <h4 class="demo-heading"><strong>We focused on 2 key metrics to evaluate models</strong></h4>
                    <li> <strong> F1 score: </strong> the harmonic mean of precision and recall</li>
                    <li> <strong> Class-Bias: </strong> The term class-bias (overpredict one class) refers specifically to one form of the term bias as used in machine learning literature.</li>

                </div>
            </div>

            <div class="portfolio-container margin-top20">
                <div class="row text-center">
                    <div class="col-md-6 col-md-offset-1 portfolio-item">
                        <a href="#portfolioResults1" class="portfolio-link" data-toggle="modal">
                            <div class="portfolio-hover">
                                <div class="portfolio-hover-content">
                                    <i class="fa fa-plus fa-3x"></i>
                                </div>
                            </div>
                            <img src="img/portfolio/filtering_graph.png" class="img-responsive" alt="">
                        </a>
                        <div class="portfolio-caption">
                            <h4>CLF. Strengths (Click for Details)</h4>
                        </div>
                    </div>
                     <div class="col-md-6 col-md-offset-1 portfolio-item">
                        <a href="#portfolioResults2" class="portfolio-link" data-toggle="modal">
                            <div class="portfolio-hover">
                                <div class="portfolio-hover-content">
                                    <i class="fa fa-plus fa-3x"></i>
                                </div>
                            </div>
                            <img src="img/portfolio/filtering_graph.png" class="img-responsive" alt="">
                        </a>
                        <div class="portfolio-caption">
                            <h4>CLF. Metrics (Click for Details)</h4>
                        </div>
                    </div>
                </div>
            </div>
        <center><br>
        <a href=" http://54.172.11.223:8080" target="_blank" class="page-scroll btn btn-xl black">View demo</a>
        </center>
        </div>
    </section>


    <!-- Second Approach Section -->
    <section id="second-approach">
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2 class="section-heading">Second Approach</h2>

                    <h3 class="section-subheading text-muted">Using *just* the 134 labeled eyes</h3>
                </div>
            </div>
            <div class="row larger">
                <div class="col-md-5">
                    <div class="portfolio-container margin-top20">
                        <div class="row text-center">
                            <div class="portfolio-item">
                                <a href="#portfolioSecondApproach" class="portfolio-link second-approach" data-toggle="modal">
                                    <div class="portfolio-hover">
                                        <div class="portfolio-hover-content">
                                            <i class="fa fa-plus fa-3x"></i>
                                        </div>
                                    </div>
                                    <img src="img/combinations.png" class="img-responsive" alt="">
                                </a>
                                <h5>Click to see mean F1-scores and Standard Deviation</h5>
                            </div>
                        </div>
                    </div>
                </div>
                <div class="col-md-7">

                    <h4>Can we use just the 134 labeled eyes to build a classifier?</h4>
                    <div class="list-item">Yes! We explored Support Vector Classifier (SVC), Random Forest and K Nearest Neighbots. We used 5-fold cross validation repeated over 1000 iterations to come up with an unbiased estimate of how well the model is doing.</div>
                    <div class="list-item">Our best model is a <b>SVC</b> that uses just the 52 pattern deviation values and age to achieve a mean F1 score of <b>0.94</b></div>

                    <h4 class="margin-top20">How can we avoid overfitting</h4>
                    <div class="list-item">Given the size of the dataset, overfitting was a concern. To address this problem, we
                        generated synthetic data.
                    </div>
                    <div class="list-item">The figure on the left shows a patient with six visual fields. We anchor the first two fields and drop fields three and four to create a synthetic data point, assuming that the final classification of stable / progressing
                        still stands.
                    By subsampling the visual fields of a patient we are able to <i>generate more than 2300 points
                        using only the 134 eyes.</i> And we got an even better average F1 score of <span class="large-and-green">0.95</span>.
                        We expect this model to generalize better to unseen data.
                    </div>
                </div>
            </div>
        </div>
    </section>


        <div class="container bottom60">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2 class="section-heading">Web App</h2>
                </div>
            </div>
            <div class="text-center">
                <img src="img/web_app_architecture.png" class="img-responsive center-block" alt="" width="900px">
                <a href=" http://54.172.11.223:8080" target="_blank" class="page-scroll btn btn-xl black">View demo</a>
            </div>
        </div>


    <!-- NextSteps Section -->
    <section id="nextsteps" class="bg-light-gray">
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2 class="section-heading">Next Steps</h2>
                    <h3 class="section-subheading text-muted">Taking our models to the next level</h3>
                </div>
            </div>
            <div class="row text-center larger">
                <div class="col-md-8 col-md-offset-2">
                    <li>Abstracts for some of the work we shared today have been submitted to the American Academy of Ophthalmology. We will continue working with our advisors.</li>
                    <li>We hope to take our models to the next level by labeling a larger portion of our dataset and exploring
                        the two approaches further.</li>
                        <li>We hope to apply the synthetic data approach to early detection of glaucoma progression.</li>
                </div>
            </div>
        </div>
    </section>


    <!-- Team Section -->
    <section id="team">
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2 class="section-heading">Our Team</h2>
                    <h3 class="section-subheading text-muted">Combining forces to push forward thinking on data-driven glaucoma detection </h3>
                </div>
            </div>
            <div class="row">
                <div class="col-sm-4" style="width: 290px;">
                    <div class="team-member">
                        <img src="img/team/loris.jpg" class="img-responsive img-square" alt="" style="width: 174px;">
                        <h4>Loris D'Acunto</h4>
                    </div>
                </div>>
                <div class="col-sm-4" style="width: 290px;">
                    <div class="team-member">
                        <img src="img/team/surabhi.jpg" class="img-responsive img-square" alt="" style="width: 174px;">
                        <h4>Surabhi Gupta</h4>
                    </div>
                </div>
                <div class="col-sm-4" style="width: 290px;">
                    <div class="team-member">
                        <img src="img/team/vikram.jpg" class="img-responsive img-square" alt="" style="width: 174px;">
                        <h4>Vikram Hegde</h4>
                    </div>
                </div>
                 <div class="col-sm-4" style="width: 290px;">
                    <div class="team-member">
                        <img src="img/team/amin.jpg" class="img-responsive img-square" alt="" style="width: 174px;">
                        <h4>Amin Venjara</h4>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Advisors Section -->
    <section id="advisors" class="bg-light-gray">
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2 class="section-heading">Our Advisors</h2>
                    <h3 class="section-subheading text-muted">Helping us chart the course and guiding us through the intricacies of applying machine learning to glaucoma</h3>
                </div>
            </div>
            <div class="row">
                <div class="col-sm-4" style="width: 290px;">
                    <div class="team-member">
                        <img src="img/team/osamah.jpg" class="img-responsive img-square" alt="" style="width: 174px; height: 174px">
                        <h4>Dr. Osamah Saeedi, MD</h4>
                        Assistant Professor of Ophthalmology
                        University of Maryland
                    </div>
                </div>>
                <div class="col-sm-4" style="width: 290px;">
                    <div class="team-member">
                        <img src="img/team/tobias.png" class="img-responsive img-square" alt="" style="width: 174px;">
                        <h4>Dr. Tobias Elze</h4>
                        Instructor in Ophthalmology
                        <br>Harvard Medical School</br>
                    </div>
                </div>
                <div class="col-sm-4" style="width: 290px;">
                    <div class="team-member">
                        <img src="img/team/joyce.png" class="img-responsive img-square" alt="" style="width: 174px;">
                        <h4>Joyce Shen</h4>
                        Lecturer
                        <br>UC Berkeley School of Information
                    </div>
                </div>
                 <div class="col-sm-4" style="width: 290px;">
                    <div class="team-member">
                        <img src="img/team/alberto.jpg" class="img-responsive img-square" alt="" style="width: 174px;">
                        <h4>Alberto Todeschini</h4>
                        Lecturer
                        <br>UC Berkeley School of Information
                    </div>
                </div>
            </div>
        </div>
    </section>



    <footer>
        <div class="container">
            <div class="row">
                <div class="col-md-12">
                    <span class="copyright">Copyright &copy; Foresight 2017</span>
                </div>
            </div>
        </div>
    </footer>

    <!-- Portfolio Modals -->
    <!-- Use the modals below to showcase details about your portfolio projects! -->

    <!-- Portfolio Modal 1 -->
    <div class="portfolio-modal modal fade" id="portfolioModal1" tabindex="-1" role="dialog" aria-hidden="true">
        <div class="modal-dialog">
            <div class="modal-content">
                <div class="close-modal" data-dismiss="modal">
                    <div class="lr">
                        <div class="rl">
                        </div>
                    </div>
                </div>
                <div class="container">
                    <div class="row">
                        <div class="col-lg-8 col-lg-offset-2">
                            <div class="modal-body">
                                <!-- Project Details Go Here -->
                                <h2>#1: User Research</h2>
                                <img class="img-responsive img-centered" src="img/portfolio/user_research.png" alt="">
                                <p align = left>In order to understand how to improve we glaucoma detection via machine learning, we interviewed five ophthalmologists and optometrists -- the target user of our product. </p>

                                <p align = left> Our objectives for the interviews were to understand:
                                <ul>
                                <li align = left> <strong> Current state detection processes: </strong> Each physician has her or his own personal "algorithm" for how to determine progression. We wanted to learn from these experience-based processes to inform our model development, but also identify potential points for improvement. </li>
                                <li align = left> <strong> Pain points: </strong> Key frustrations opthalmologists and optometrists face today when trying to determine progression of glaucoma-suspect patients. </li>
                                <li align = left> <strong> Concept feedback: </strong> Gathering unprompted and prompted reactions to paper prototypes of product concepts  </li>
                                </ul>
                                </p>

                                <p align = left>Key learnings from the interviews included:
                                <ul>
                                <li align = left> <strong> Test variation is a key challenge: </strong> Visual field tests have a high degree of variance due to patient focus, technician skills and also a learning effect. All of these complicate the ability to get a clear picture of progression </li>
                                <li align = left> <strong> Primarily manual, paper-based process: </strong> Determining progression today is a very manual process. Clinicians typically line up print-outs from visual field machines and manually look for patterns. Electronic Medical Record (EMR) systems are starting to make in-roads but are primarily digitization of existing paper than real leaps forward in any analytics</li>
                                <li align = left> <strong> Clinicians want the raw data: </strong> Due to test variability and lack of gold standard metrics, clinicians grown accustomed to looking at the raw data to sanity check the results of existing algorithms. Making raw data easily available is important for securing a clinician's trust </li>
                                <li align = left> <strong> Advanced algorithm have limited adoption today: </strong> While clinicians are aware of progression algorithms from recent, large research studies (e.g., AGIS, CIGTS), they are not well understood and rarely used clincially as they require extensive, manual calculations. Instead, clinicians tend to stick with the methods they learned during their training</li>
                                <li align = left> <strong> Greyscale images of eye are important for patient education: </strong> Clincians regularly use greyscale images to help patients understand their diagnosis and progression. Patient education is important ensure treatment adherence and attendance at follow-up visits  </li>
                                </ul>
                                 </p>

                                <p align = left>The next steps for user research would include testing our web-based prototype with clincians and expanding our research to include patients to test for success in enabling patient education. </p>


                                <button type="button" class="btn btn-primary" data-dismiss="modal"><i class="fa fa-times"></i> Back to Main Page</button>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>

    <!-- Portfolio Modal 2 -->
    <div class="portfolio-modal modal fade" id="portfolioModal2" tabindex="-1" role="dialog" aria-hidden="true">
        <div class="modal-dialog">
            <div class="modal-content">
                <div class="close-modal" data-dismiss="modal">
                    <div class="lr">
                        <div class="rl">
                        </div>
                    </div>
                </div>
                <div class="container">
                    <div class="row">
                        <div class="col-lg-8 col-lg-offset-2">
                            <div class="modal-body">
                                <!-- Project Details Go Here -->
                                <h2>#2: Data Filtering</h2>
                                <img class="img-responsive img-centered" src="img/portfolio/filtering_graph.png" alt="">
                                <p align = left>The initial dataset had 177,172 patients with 831,240 visual fields (VF) from 5 different institutions. We focused our analysis on the most commonly used methods, the SITA (see above) on  24-2 field measurement (which measures 24 degrees temporally and 30 degrees nasally and tests 54 points spaced 2 degrees apart). The stimulus size was III (code for a particular standard size) and was white on a white background. These criteria were selected for us by our opthalomologist advisor as current best clinical practice.
                                </p>
                                <p align = left> From the raw data, we removed tests with high level of false positive (greater than 20%) and we kept only the VFs where there were at least 5 studies conducted on the same eye. The criteria for grouping studies was [patient-id, eye (OD or OS)]. OD is the medical term for the right eye and OS for the left eye. Thus each eye’s (left or right) studies were considered separate. After this filtering process, we ended up with a final dataset of 90,713 visual fields of 13,156 eyes included in the study.</p>

                                <button type="button" class="btn btn-primary" data-dismiss="modal"><i class="fa fa-times"></i> Back to Main Page</button>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>

    <!-- Portfolio Modal 3 -->
    <div class="portfolio-modal modal fade" id="portfolioModal3" tabindex="-1" role="dialog" aria-hidden="true">
        <div class="modal-dialog">
            <div class="modal-content">
                <div class="close-modal" data-dismiss="modal">
                    <div class="lr">
                        <div class="rl">
                        </div>
                    </div>
                </div>
                <div class="container">
                    <div class="row">
                        <div class="col-lg-8 col-lg-offset-2">
                            <div class="modal-body">
                                <!-- Project Details Go Here -->
                                <h2>#3: Data Exploration</h2>
                                <img class="img-responsive img-centered" src="img/portfolio/exploring_data.png" alt="">
                                <p align = left>Glaucoma is known to be a disease that is more prevalent in older patients and our data confirms this. As the histogram below shows, the prevalence of Glaucoma increases with age with the average age of the patient being 67 years. The fall off in the prevalence of glaucoma beyond the peak reflects possibly two trends - patients reaching the end of their life span before Glaucoma occurs and saturation of Glaucoma incidence in the Glaucoma susceptible population.
                                </p>
								<img class="img-responsive img-centered" src="img/portfolio/age_big.png" alt="">
                                <p align = left> The typical HFA test can be tedious for most subjects and this may result in errors (false positives or negatives) in patients. This situation can be exacerbated in older patients due to their age. The average duration of the test is more than 6 minutes, but higher rate of errors may prolong the test.
                                </p>
                                <img class="img-responsive img-centered" src="img/portfolio/test.png" alt="">
								<p align = left>As expected, there is a correlation between the duration of the test and the age of the patients.
                                </p>
                                <img class="img-responsive img-centered" src="img/portfolio/duration_vs_age.png" alt="">
								<p align = left>The results provided by the HFA include false positive and false negative errors as well as both global indices and point wise measures. Some of them are:
								<ul>
                                <li align = left><b>Mean Deviation</b> (MD) a global index of the deviation away from age matched controls.  Patients without glaucoma have MD values close to zero. Patients having Mean Deviation more negative than -10 dB are classed as having advanced Glaucoma. As we can see from the relative picture, the majority of the patients had negative MD indicating Glaucoma vision loss.</li>
                                <li align = left><b>Raw Sensitivity</b>, (point wise metric) values of each tested point in decibels.</li>
                                <li align = left><b>Total Deviation</b>, (point wise metric) this is the deviation of each point in the visual field compared to control subjects for that specific age set. Patients without glaucoma have values close to zero.</li>
                                <li align = left><b>Pattern Deviation</b>, is the total deviation after reducing deviations uniformly across the visual field. The rationale is that this accounts for global deficits in VFs caused by other reasons such as cataract, leaving the typical localized Glaucoma related deficit in place.</li>
                                </ul>
                                </p>
								<img class="img-responsive img-centered" src="img/portfolio/md.png" alt="">
								<img class="img-responsive img-centered" src="img/portfolio/sensitivity.png" alt="">
								<img class="img-responsive img-centered" src="img/portfolio/td.png" alt="">
								<img class="img-responsive img-centered" src="img/portfolio/ptd.png" alt="">
								<p align = center><b>Spatial correlation</b></p>
								<p align = left>The picture below, on the left side, shows the structure of the retinal nerve fibre bundles that are visible after a digital enhancement of a picture taken with a blue filter. In the right side, the same structure is manually highlighted in red. The retinal nerves transmit the visual information from the retina to the brain.
                                </p>
								<img class="img-responsive img-centered" src="img/portfolio/eye.png" alt="">
								<p align = left>Overlapping the structure of the retinal nerves with the visual fields matrix, suggests a complex spatial correlation between the points.
                                </p>
								<img class="img-responsive img-centered" src="img/portfolio/vf-eye.png" alt="">
								<p align = left>The following plots display the spatial correlation obtained by analyzing the correlation matrixes of the raw sensitivities, the total deviations and the pattern deviations. The 2 lines without data correspond to the position of the blind spot.
                                </p>
								<p align = center><b>Correlation matrix of the total deviations</b></p>
								<img class="img-responsive img-centered" src="img/portfolio/corr_td.png" alt="">
								<p align = center><b>Correlation matrix of the pattern deviations</b></p>
								<img class="img-responsive img-centered" src="img/portfolio/corr_pd.png" alt="">
								<p align = left>Visual field deficits in Glaucoma are caused by damage to the nerve fibers that conduct nerve impulses to the brain. The above described complex spatial correlations between VF points result in patterns of visual field loss that cannot be summarized by a single metric. <u>This was the rationale for our decision to use point-wise data rather than a global index as the input to our classifiers.</u> A global index typically loses most of the spatial information encoded in the sensitivity of VF points.</p>
                                <button type="button" class="btn btn-primary" data-dismiss="modal"><i class="fa fa-times"></i> Back to Main Page</button>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>

    <!-- Portfolio Modal 4 -->
    <div class="portfolio-modal modal fade" id="portfolioModal4" tabindex="-1" role="dialog" aria-hidden="true">
        <div class="modal-dialog">
            <div class="modal-content">
                <div class="close-modal" data-dismiss="modal">
                    <div class="lr">
                        <div class="rl">
                        </div>
                    </div>
                </div>
                <div class="container">
                    <div class="row">
                        <div class="col-lg-8 col-lg-offset-2">
                            <div class="modal-body">
                                <!-- Project Details Go Here -->
                                <h2>#4: Data Normalization</h2>
                                <img class="img-responsive img-centered" src="img/portfolio/normalizing.png" alt="">
                                <p align = left>Different patients have different number of visual fields, but for our machine learning models, we need to provide a fixed length input.
                                Moreover, there was a lot of variation in the temporal range of the VF recordings. For one patient the fields may be 10 years apart, for another it may be 2 years apart. So we had to normalize the time dimension in our training dataset and to do that we explored a few different solutions:

                                <ul>
                                <li align = left> We divided the visual fields for each patient into two groups (first half and second half) and calculated the difference in pointwise means between the two groups. We then divide the delta (in pointwise means) by the time spanned by the visual fields.</li>
                                <li align = left> Like the previous approach but without dividing by time </li>
                                <li align = left> Instead of taking all the visual fields, we took the first and the last two visual fields. </li>
                                </ul>

                                <p align = left> The second approach gave us the best results with our classifiers.</p>

                                <button type="button" class="btn btn-primary" data-dismiss="modal"><i class="fa fa-times"></i> Back to Main Page</button>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>

    <!-- Portfolio Modal 5 -->
    <div class="portfolio-modal modal fade" id="portfolioModal5" tabindex="-1" role="dialog" aria-hidden="true">
        <div class="modal-dialog">
            <div class="modal-content">
                <div class="close-modal" data-dismiss="modal">
                    <div class="lr">
                        <div class="rl">
                        </div>
                    </div>
                </div>
                <div class="container">
                    <div class="row">
                        <div class="col-lg-8 col-lg-offset-2">
                            <div class="modal-body">
                                <!-- Project Details Go Here -->
                                <h2>#5: Label Generation</h2>
                                <img class="img-responsive img-centered" src="img/portfolio/generating_labels_1.png" alt="">
                                <p align = left>In order to apply a classifier to the dataset, we had to assign a label to every single eye of the patients who met our inclusion criteria (described previously). We used two labels: (1) Stable: vision in a specific eye of the patient is stable or not decreasing at a rate that is measurable (2) Progressing: the eye of the patient is measurably getting worse. Note that it is quite possible that the left eye of a patients has severe glaucoma while the right eye is disease free (or vice versa). Hence each eye (left or right) was considered separately as a single sample.</p>

                                <p align = left>
                                We used 6 methods to determine the same metric - the progression of visual field loss (or lack thereof):
                                <ul>
                                <li align = left><b> AGIS Score </b> - Advanced Glaucoma Intervention Study </li>
                                <li align = left><b> CIGTS Score </b> - Collaborative Initial Glaucoma Treatment Study </li>
                                <li align = left><b> Mean Deviation </b> - (provided by the HFA) </li>
                                <li align = left><b> VFI index - calculated using an open source R package</b></li>
                                <li align = left><b> PLR </b>- Pointwise Linear Regression </li>
                                <li align = left><b> PoPLR </b>- Permutation of Pointwise Linear Regression </li>
                                </ul>
                                </p>

                                <p align = left>
                                The first 4 algorithms evaluate the severity of vision loss in a patient (how bad is it ?). The last two algorithms measure “progression” of visual loss (is it getting worse with time.)
                                Since the quantity we are actually interested in is progression i.e. is there a measurable rate of loss -  for the severity measures we compute rate of severity increase across multiple VF studies to get the progression. </p>

                                <p align = left>
                                None of these indices (Except MD) are readily available in the data to use. For the rest, we either implemented the algorithms ourselves (AGIS, CIGTS) or we used open source R packages (rest of the indices). The open source package we used was the R package “visualFields” developed by Ivan Marin-Franch.
                                One important finding from generating the labels is that the 6 different approaches result in 6 different verdicts. The following table is an extract from the table we developed for all our 10,000 or so eyes.
                                </p>

                                <img class="img-responsive img-centered" src="img/portfolio/labels_table.png" alt="">

                                <p align = left>
                                For machine learning, we needed a singe label for each eye. So we decided to use a voting system. The winning vote (progressing or stable) became the training label for our classifier.
                                </p>
								<p align = left>
								After the labeling we analyzed the data using a Principal Component Analysis and it’s clear from the following set of pictures that there are two distinct regions (one for stable and one for progressing) and then a big overlap between the two clusters. The first chart is created plotting the stable patients first, the second plotting the progressing first.
								</p>
								<p align = center>
								<b>Chart plotting the stable patients first</b>
								</p>
								<img class="img-responsive img-centered" src="img/portfolio/pca1.png" alt="">
								<p align = center>
								<b>Chart plotting the progressing patients first</b>
								</p>
								<img class="img-responsive img-centered" src="img/portfolio/pca2.png" alt="">
								<p align = left>The following chart presents the final result with the “boundary” patients i.e. patients who are neither measurably stable or measurably progressing.
								</p>
								<img class="img-responsive img-centered" src="img/portfolio/pca3.png" alt="">
								<p align = left>
								From the figures it’s clear that the "boundary" patients are those in the intersection between the 2 sets. It’s very complex to study the data using unsupervised clustering. In fact both group of patients are losing their sight, but the ones that are classified as “stable” are losing it at a imprerciptible slower speed compared to the “progressing” ones. Basically it’s human perception that divides a patient into progressing or stable. In reality there exists a continuum between the two states and their overlap.
								</p>
                                <button type="button" class="btn btn-primary" data-dismiss="modal"><i class="fa fa-times"></i> Back to Main Page</button>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>

     <!-- Portfolio Modal 6 -->
    <div class="portfolio-modal modal fade" id="portfolioModal6" tabindex="-1" role="dialog" aria-hidden="true">
        <div class="modal-dialog">
            <div class="modal-content">
                <div class="close-modal" data-dismiss="modal">
                    <div class="lr">
                        <div class="rl">
                        </div>
                    </div>
                </div>
                <div class="container">
                    <div class="row">
                        <div class="col-lg-8 col-lg-offset-2">
                            <div class="modal-body">
                                <!-- Project Details Go Here -->
                                <h2>#6: Model Development</h2>
                                <img class="img-responsive img-centered" src="img/portfolio/generating_models.png" alt="">
                                <p align = left>We applied different classifiers to our dataset and in particular:
								<ul>
                                <li align = left><b> Logistic Regression </b></li>
                                <li align = left><b> Random Forest </b> </li>
                                <li align = left><b> Extreme Gradient Boosting </b></li>
                                <li align = left><b> Support Vector Classifier </b></li>
                                <li align = left><b> Vanilla Neural Network </b></li>
                                <li align = left><b> Convolutional Neural Network </b></li>
                                </ul>
								</p>
                                <p align = left>
                                Our goal in modelling was not to come up with a perfect classifier for the proxy label we used (majority vote label). Our hypothesis instead was that the proxy label reflected a strong "true" signal corrupted by noise caused by our imperfect proxy label. We tuned our hyperparameters to deliberately underfit to the noisy label. The tuning was carried out by assuming that within each category of stable and progressing, there exists (given sufficient eyes) a normal distribution of eyes. We felt that 10,000 eyes was a sufficiently large population of eyes to give us a reasonably accurate normal distribution within each category. We then started fitting models to the training set using the simplest and least expressive model possible (for a random forest, the hyperparameter we used was maximum depth of the trees in the forest). We then increased the max-depth hyperparameter until we had a reasonably accurate normal distribution of eyes in each of the stable and progressing categories. In other words we chose the simplest model that resulted in a normal distribution of eyes in each class. By underfitting in this fashion, our hypothesis was that we would be picking out the hypothesized strong signal in the data (without being affected by the noise introduced by our proxy labels.)
                                </p>

                                <p align = left>
                                In the rest of this section we discuss the challenges we faced in developing some of models, particularly convolutional neural networks.
                                </p>>
								<p align = left>
								The structure of the <b>Neural Network </b> is described in the following table. To avoid overfitting we added 4 dropout layers with decreasing dropout probabilities, from 0.5 to 0.2.
								</p>
                               <img class="img-responsive img-centered" src="img/portfolio/NN.png" alt="">
								<p align = left>
								We trained the Neural Network for 20,000 epochs since we found that more training didn’t improve the accuracy of the classifications. For our model we used Keras with a Tensorflow backend and we noticed that the model loss on the validation set was smaller that the one one the training set. We believe we have a reasonable explanation for why this is so (the following is adapted from the Keras documentation):
								<ul>
                                <li align = left>1. During the calculation of the validation set accuracy, regularization mechanisms such as Dropout are turned off</li>
                                <li align = left>2. The training loss is the average of the losses over an epoch. Typically a model is worse at the start of an epoch compared to the end of an epoch. A model whose accuracy is the average accuracy across the epoch will typically fare worse than the (validation) accuracy measured at the end of the epoch (unless there is strong overfitting.)</li>
                                </ul>
								</p>
								<img class="img-responsive img-centered" src="img/portfolio/NN_training.png" alt="">
                                <p align = left>
								For the <b>Convolutional Neural Network</b> we had to rectify the shape of the matrix of the visual fields. We manipulated the data in the way described in the following picture, adding zero valued padding where needed:
								</p>
								<img class="img-responsive img-centered" src="img/portfolio/CNN_shape.png" alt="">
								<p align = left>
								The following table describe the structure of the classifier, that we trained for 300 epochs. More training didn't improve the capability of the network to correctly classify the patients. Also in this case we added some dropout layers to avoid overfitting. In particular the dropout probabilities were 0.2 for both layers.
								</p>
								<img class="img-responsive img-centered" src="img/portfolio/CNN.png" alt="">
								<img class="img-responsive img-centered" src="img/portfolio/CNN_training.png" alt="">
                                <button type="button" class="btn btn-primary" data-dismiss="modal"><i class="fa fa-times"></i> Back to Main Page</button>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>



     <!-- Portfolio Modal Results 1 -->

    <div class="portfolio-modal modal fade" id="portfolioResults1" tabindex="-1" role="dialog" aria-hidden="true">
        <div class="modal-dialog">
            <div class="modal-content">
                <div class="close-modal" data-dismiss="modal">
                    <div class="lr">
                        <div class="rl">
                        </div>
                    </div>
                </div>
                <div class="container">
                    <div class="modal-body">

                        <h2><strong>Classifier Strengths</strong></h2>
                        <img class="img-responsive img-centered" src="img/f1-score.jpg" alt="">

                        <p align = left>
                            <strong>Encouraging F1 scores: </strong> Our top 4 classifiers had F1 scores in line with leading research algorithms (i.e., 0.90 or above)
                            <br><br>
                            <strong>Lower Class-Bias: </strong> Our classifiers did not overpredict "progressing" on patients identified as "too close to call" by the glaucoma specialist, while VFI and PLR did. On the set of 66 "too close to call" patients -- PLR and VFI identified 63/66 (95%) and 59/66 (89%) patients as progressing, which suggests very strong tendency to overpredict in cases that were not clear even to human experts.
                        </p>
                        <br>
                        <button type="button" class="btn btn-primary" data-dismiss="modal"><i class="fa fa-times"></i> Back to Main Page</button>
                    </div>
                </div>
            </div>
        </div>
    </div>

    <!-- Portfolio Modal Results 2 -->
    <div class="portfolio-modal modal fade" id="portfolioResults2" tabindex="-1" role="dialog" aria-hidden="true">
        <div class="modal-dialog">
            <div class="modal-content">
                <div class="close-modal" data-dismiss="modal">
                    <div class="lr">
                        <div class="rl">
                        </div>
                    </div>
                </div>
                <div class="container">
                    <div class="modal-body">
                        <!-- Project Details Go Here -->
                        <h2><strong>Classifier Metrics</strong></h2>
                        <img class="img-responsive img-centered" src="img/class_biased_classifier.jpg"  alt="">

                        <p align = left>
                            <strong> Class-Bias: </strong> The term class-bias in our case refers specifically to one form of the term bias as used in machine learning literature. In machine learning, bias (i.e. ML-bias) refers to any systematic deviation from the true model across many training sets. The bias we are referring to here (class-bias) is the tendency of a classifier to overpredict one class or the other.
                        </p>

                        <p align = left> Unless the class-bias is overwhelmingly in favor of one class, clearly demarcable cases tend to be predicted correctly despite class-bias. A good way to
                            determine if there is any hidden class-bias is to look at the examples straddling the boundary between "progressing" and "stable". Class-bias (if any) in these cases cannot be ignored, since fully 1/3 of all eyes submitted to a human expert for labelling were classified as "boundary" eyes.
                            <br><br>
                            To ensure that our determination of hidden class-bias was statistically sound, we conducted a chi-squared analysis to determine if the distribution of predictions for the "boundary" eyes was significantly different from the distribution of the ground truth for eyes that had a clear demarcation. A large p-value implies no statistically significant difference in distributions, which indicates a balanced classifier. A small p value shows differences that are statistically significant, indicating that the classifier is biased.
                            <br><br>
                            Many of the ophthalmological indices had p values less than 0.05. This indicates that there was a very strong class-bias towards either the "progressing" or "stable" label irrespective of F1-scores. All of the machine learning classifiers on the other hand seem not to have class-bias.
                        </p>
                        <p align = left>
                        <strong> F1 score: </strong> the harmonic mean of precision (what fraction of a predicted label is really that label) and recall (what fraction of a particular label is actually predicted).
                        </p>
                        <br>
                        <button type="button" class="btn btn-primary" data-dismiss="modal"><i class="fa fa-times"></i> Back to Main Page</button>
                    </div>
                </div>
            </div>
        </div>
    </div>

    <!-- Portfolio Second Approach -->
    <div class="portfolio-modal modal fade" id="portfolioSecondApproach" tabindex="-1" role="dialog" aria-hidden="true">
        <div class="modal-dialog">
            <div class="modal-content">
                <div class="close-modal" data-dismiss="modal">
                    <div class="lr">
                        <div class="rl">
                        </div>
                    </div>
                </div>
                <div class="container">
                    <div class="modal-body">
                        <!-- Project Details Go Here -->
                        <img class="img-responsive img-centered" src="img/second-approach-results.png"  alt="">
                        <br>
                        <button type="button" class="btn btn-primary black" data-dismiss="modal"><i class="fa fa-times"></i> Back to Main Page</button>
                    </div>
                </div>
            </div>
        </div>
    </div>

    <!-- jQuery -->
    <script src="vendor/jquery/jquery.min.js"></script>

    <!-- Bootstrap Core JavaScript -->
    <script src="vendor/bootstrap/js/bootstrap.min.js"></script>

    <!-- Plugin JavaScript -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-easing/1.3/jquery.easing.min.js" integrity="sha384-mE6eXfrb8jxl0rzJDBRanYqgBxtJ6Unn4/1F7q4xRRyIw7Vdg9jP4ycT7x1iVsgb" crossorigin="anonymous"></script>

    <!-- Theme JavaScript -->
    <script src="js/agency.min.js"></script>

</body>

</html>
